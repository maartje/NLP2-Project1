{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datasets\n",
    "import debug_helpers\n",
    "\n",
    "import collections\n",
    "import aer\n",
    "\n",
    "# pretty print variabeles on line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_jump_probs(sentence_pairs):\n",
    "    max_jump = 0\n",
    "    for (s_sentence, t_sentence) in sentence_pairs:\n",
    "        s_length = len(s_sentence) - 1 #ignore NULL\n",
    "        t_length = len(t_sentence)\n",
    "        jump_1 = abs(1 - math.floor(s_length))\n",
    "        jump_2 = abs(s_length - math.floor(s_length/t_length))\n",
    "        max_jump = max(jump_1, jump_2, max_jump)\n",
    "    init_prob = 1. / (2*max_jump + 1 + 1) # last item is special NULL jump prob\n",
    "    return [init_prob] * (2*max_jump + 1 + 1)\n",
    "\n",
    "# s_pos and s_length for source sentence including special NULL word\n",
    "def get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    if s_pos == 0:\n",
    "        return len(jump_probs) - 1\n",
    "    jump = int(s_pos - math.floor((t_pos + 1) * (s_length - 1) / t_length))\n",
    "    max_jump = int((len(jump_probs) - 2)/2)\n",
    "    jump_prob_index = jump + max_jump\n",
    "    if jump_prob_index < 0:\n",
    "        raise IndexError('Index is expected to be positive.')\n",
    "    return jump_prob_index\n",
    "\n",
    "def get_jump_prob(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    jump_prob_index = get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "    return jump_probs[jump_prob_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alignment_prob(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    jump_prob = get_jump_prob(\n",
    "        s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "    sum_jump_probs = sum([\n",
    "        get_jump_prob(\n",
    "            s_word_pos, t_pos, s_length, t_length, jump_probs\n",
    "        ) for s_word_pos in range(s_length)])\n",
    "    return jump_prob / sum_jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {Hause: { book:0.25, ...}, ...}\n",
    "# read: the probability of 'book' given 'Haus' is 0.25\n",
    "def _initialize_lexicon_probabilities(source_vocabulary, target_vocabulary):\n",
    "    p_init = 1./len(target_vocabulary)\n",
    "    lexicon_probabilities = collections.defaultdict(\n",
    "        lambda: collections.defaultdict(lambda: p_init))\n",
    "    return lexicon_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _likelihood_target_word(s_sentence, t_word, lprobs):\n",
    "    return sum([lprobs[s_word][t_word] for s_word in s_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align(lprobs, sentence_pairs):\n",
    "    if isinstance(sentence_pairs, tuple):\n",
    "        return _align_sentence_pair(lprobs, sentence_pairs)\n",
    "    return [ _align_sentence_pair(lprobs, sentence_pair) for sentence_pair in sentence_pairs ]\n",
    "\n",
    "def _align_sentence_pair(lprobs, sentence_pair):\n",
    "    s_sentence = sentence_pair[0]\n",
    "    t_sentence = sentence_pair[1]\n",
    "    best_alignment = set()\n",
    "    for j, t_word in enumerate(t_sentence):\n",
    "        best_align_prob = -1\n",
    "        best_align_pos = -1\n",
    "        for i, s_word in enumerate(s_sentence):\n",
    "            if s_word not in lprobs.keys() or t_word not in lprobs[s_word].keys():\n",
    "                continue # ignore unseen source and target words\n",
    "            align_prob = lprobs[s_word][t_word] #p(t|s)\n",
    "            if align_prob >= best_align_prob:\n",
    "                best_align_pos = i\n",
    "                best_align_prob = align_prob\n",
    "        if (best_align_pos > 0): # Leave out NULL-alignments (and alignments between unseen words)\n",
    "            best_alignment.add((best_align_pos, j + 1)) # word positions start at 1\n",
    "    return best_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM(s_t_pairs, s_vocabulary, t_vocabulary, max_iterations = 10,\n",
    "        val_sentence_pairs = None, reference_alignments = None, fn_debug = None):\n",
    "    lprobs = _initialize_lexicon_probabilities(s_vocabulary, t_vocabulary)\n",
    "    i = 0\n",
    "    log_likelihoods = []\n",
    "    AERs = []\n",
    "    while i < max_iterations:\n",
    "        # initialize\n",
    "        log_likelihood = 0\n",
    "        AER = 0\n",
    "        counts_t_given_s = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "        total_s = collections.defaultdict(int)\n",
    "\n",
    "        # calculate counts and log likelihood\n",
    "        for (s_sentence, t_sentence) in s_t_pairs:\n",
    "            s_length = len(s_sentence)\n",
    "            t_length = len(t_sentence)\n",
    "            for t_pos, t_word in enumerate(t_sentence):\n",
    "                # normalization factor\n",
    "                s_total_t = _likelihood_target_word(s_sentence, t_word, lprobs)\n",
    "                # likelihood_target_position: sum thing\n",
    "                # s_total_t = product of both\n",
    "                log_likelihood += math.log(s_total_t)\n",
    "                for s_pos, s_word in enumerate(s_sentence):\n",
    "                    update = lprobs[s_word][t_word]/s_total_t\n",
    "                    counts_t_given_s[s_word][t_word] += update\n",
    "                    total_s[s_word] += update\n",
    "        \n",
    "        # store log_likelihood and AER values\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "        if val_sentence_pairs and reference_alignments:\n",
    "            predicted_alignments = align(lprobs, val_sentence_pairs)\n",
    "            AER = aer.calculate_AER(reference_alignments, predicted_alignments)\n",
    "            AERs.append(AER)\n",
    "\n",
    "        # print debug info\n",
    "        if fn_debug:\n",
    "            fn_debug(i, lprobs, log_likelihood, AER)\n",
    "\n",
    "        # update probabilities\n",
    "        for s in lprobs.keys():\n",
    "            for t in lprobs[s].keys():\n",
    "                lprobs[s][t] = counts_t_given_s[s][t]/total_s[s]\n",
    "\n",
    "        # update iteration number\n",
    "        i += 1\n",
    "    return lprobs, log_likelihoods, AERs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['das', 'Haus'], ['the', 'house']),\n",
       " (['das', 'Buch'], ['the', 'book']),\n",
       " (['ein', 'Buch'], ['a', 'book'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  log_likelihood  likelihood  AER\n",
      "0 -4.159 0.016 0.00000\n",
      "1 -1.151 0.316 0.00000\n",
      "2 -0.842 0.431 0.00000\n",
      "3 -0.586 0.557 0.00000\n",
      "4 -0.390 0.677 0.00000\n",
      "5 -0.252 0.777 0.00000\n",
      "6 -0.159 0.853 0.00000\n",
      "7 -0.100 0.905 0.00000\n",
      "8 -0.062 0.940 0.00000\n",
      "9 -0.039 0.961 0.00000\n",
      "das the 0.9933053397165424\n",
      "das house 0.0046110887522225865\n",
      "das book 0.0020835715312351013\n",
      "Haus the 0.08276408100718743\n",
      "Haus house 0.9172359189928124\n",
      "Buch the 0.0020835715312350995\n",
      "Buch book 0.9933053397165423\n",
      "Buch a 0.004611088752222586\n",
      "ein a 0.9172359189928124\n",
      "ein book 0.08276408100718743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run EM on toy example\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data()\n",
    "s_t_pairs\n",
    "(lprobs, _, _) = EM(s_t_pairs, s_vocabulary, t_vocabulary, \n",
    "                 fn_debug = debug_helpers.print_likelihood)\n",
    "\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['<NULL>', 'das', 'Haus'], ['the', 'house']),\n",
       " (['<NULL>', 'das', 'Buch'], ['the', 'book']),\n",
       " (['<NULL>', 'ein', 'Buch'], ['a', 'book']),\n",
       " (['<NULL>', 'ein', 'Haus'], ['a', 'small', 'house']),\n",
       " (['<NULL>', 'mein', 'Buch'], ['my', 'small', 'book'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  log_likelihood  likelihood  AER\n",
      "0 -8.318 0.000 0.75000\n",
      "1 -3.214 0.040 0.25000\n",
      "2 -2.152 0.116 0.14286\n",
      "3 -1.373 0.253 0.14286\n",
      "4 -0.865 0.421 0.14286\n",
      "5 -0.544 0.580 0.14286\n",
      "6 -0.338 0.713 0.14286\n",
      "7 -0.202 0.817 0.14286\n",
      "8 -0.109 0.896 0.14286\n",
      "9 -0.045 0.956 0.14286\n",
      "10 -0.000 1.000 0.14286\n",
      "11 0.031 1.032 0.14286\n",
      "12 0.054 1.055 0.14286\n",
      "13 0.070 1.072 0.14286\n",
      "14 0.081 1.085 0.14286\n",
      "15 0.090 1.094 0.14286\n",
      "16 0.096 1.101 0.14286\n",
      "17 0.101 1.106 0.14286\n",
      "18 0.104 1.110 0.14286\n",
      "19 0.107 1.113 0.14286\n",
      "<NULL> the 0.002703782024438147\n",
      "<NULL> house 0.0047664944727924\n",
      "<NULL> book 0.23131096714592353\n",
      "<NULL> a 0.0049385156306393915\n",
      "<NULL> small 0.756279473085454\n",
      "<NULL> my 7.676407527728933e-07\n",
      "das the 0.9999984381034837\n",
      "das house 1.5359743961192934e-06\n",
      "das book 2.5922120144793404e-08\n",
      "Haus the 4.917775659561484e-07\n",
      "Haus house 0.9992092174629266\n",
      "Haus a 8.766652745862759e-07\n",
      "Haus small 0.0007894140942328188\n",
      "Buch the 1.2226865092224424e-08\n",
      "Buch book 0.9999961375254085\n",
      "Buch a 2.2861551201309313e-08\n",
      "Buch my 3.3186398260819336e-06\n",
      "Buch small 5.087463490999096e-07\n",
      "ein a 0.9992370410789507\n",
      "ein book 1.602017784274745e-08\n",
      "ein small 0.0007619379939570765\n",
      "ein house 1.0049069143525652e-06\n",
      "mein my 0.8670263167073299\n",
      "mein small 0.13291483749809788\n",
      "mein book 5.88457945722153e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run EM on toy example with NULL words\n",
    "val_sentence_pairs = [(\n",
    "    ['<NULL>', 'Buch', 'klein', 'das', 'Haus'], \n",
    "    ['the', 'small', 'house', 'book']\n",
    ")]\n",
    "ref_alignments = [[\n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}, \n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}\n",
    "]]\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs\n",
    "(lprobs, _, _) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 20,\n",
    "    val_sentence_pairs, ref_alignments, debug_helpers.print_likelihood)\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run EM on training data set with AER on validation set\n",
    "val_sentence_pairs, _, _ = datasets.validation_data()\n",
    "reference_alignments = datasets.validation_alignments()    \n",
    "\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.training_data()\n",
    "(lprobs, log_lhoods, AERs) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 30,\n",
    "    val_sentence_pairs, reference_alignments, \n",
    "    debug_helpers.print_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
