{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datasets\n",
    "import debug_helpers\n",
    "\n",
    "import collections\n",
    "import aer\n",
    "import warnings\n",
    "\n",
    "# pretty print variabeles on line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns list with jump probabilities \n",
    "# (and special NULL jump probability)\n",
    "# [-max_jump ....0 ...max_jump, NULL_jump]\n",
    "def _initialize_jump_probs(sentence_pairs):\n",
    "    max_jump = 0\n",
    "    for (s_sentence, t_sentence) in sentence_pairs:\n",
    "        s_length = len(s_sentence) - 1 #ignore NULL\n",
    "        t_length = len(t_sentence)\n",
    "        jump_1 = abs(1 - math.floor(s_length))\n",
    "        jump_2 = abs(s_length - math.floor(s_length/t_length))\n",
    "        max_jump = max(jump_1, jump_2, max_jump)\n",
    "    init_prob = 1. / (2*max_jump + 1 + 1) # last item is special NULL jump prob\n",
    "    return [init_prob] * (2*max_jump + 1 + 1)\n",
    "\n",
    "# returns the index in the jump_probabilities list\n",
    "# for given source and target positions and sentence lengths\n",
    "# s_pos and s_length for source sentence including the special NULL word\n",
    "# sentence positions start at index 0\n",
    "def get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    if s_pos == 0:\n",
    "        return len(jump_probs) - 1\n",
    "    jump = int(s_pos - math.floor((t_pos + 1) * (s_length - 1) / t_length))\n",
    "    max_jump = int((len(jump_probs) - 2)/2)\n",
    "    jump_prob_index = jump + max_jump\n",
    "    if jump_prob_index < 0:\n",
    "        warnings.warn(\n",
    "            f'Jump prob index {jump_prob_index} (jump:{jump}) out of range.'\n",
    "        )\n",
    "        return 0 #approximate with prob of largest negative jump\n",
    "    if jump_prob_index >= len(jump_probs) - 1:\n",
    "        warnings.warn(\n",
    "            f'Jump prob index {jump_prob_index} (jump:{jump}) out of range.'\n",
    "        )\n",
    "        return len(jump_probs) - 2 #approximate with prob of largest positive jump\n",
    "\n",
    "    return jump_prob_index\n",
    "\n",
    "# returns jump probability for given source and target positions\n",
    "# and lengths. Positions start at index 0, source sentence contains\n",
    "# special NULL word at position 0\n",
    "def get_jump_prob(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    jump_prob_index = get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "    return jump_probs[jump_prob_index]\n",
    "\n",
    "def get_alignment_prob(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    jump_prob = get_jump_prob(\n",
    "        s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "    sum_jump_probs = sum([get_jump_prob(\n",
    "        s_word_pos, t_pos, s_length, t_length, jump_probs\n",
    "    ) for s_word_pos in range(s_length)])\n",
    "    return jump_prob / sum_jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {Hause: { book:0.25, ...}, ...}\n",
    "# read: the probability of 'book' given 'Haus' is 0.25\n",
    "def _initialize_lexicon_probabilities(source_vocabulary, target_vocabulary):\n",
    "    p_init = 1./len(target_vocabulary)\n",
    "    lexicon_probabilities = collections.defaultdict(\n",
    "        lambda: collections.defaultdict(lambda: p_init))\n",
    "    return lexicon_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_dependencies(s_sentence, t_word, t_pos, t_length, lprobs, jump_probs):\n",
    "    s_length = len(s_sentence)\n",
    "    return [\n",
    "        get_alignment_prob(s_pos, t_pos, s_length, t_length, jump_probs) * lprobs[s_word][t_word] \n",
    "        for s_pos, s_word in enumerate(s_sentence)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _likelihood_target_word(s_sentence, t_word, t_pos, t_length, lprobs, jump_probs):\n",
    "    return sum(source_dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align(lprobs, jump_probs, sentence_pairs):\n",
    "    if isinstance(sentence_pairs, tuple):\n",
    "        return _align_sentence_pair(lprobs, jump_probs, sentence_pairs)\n",
    "    return [ _align_sentence_pair(lprobs, jump_probs, sentence_pair) for sentence_pair in sentence_pairs ]\n",
    "\n",
    "def _align_sentence_pair(lprobs, jump_probs, sentence_pair):\n",
    "    s_sentence = sentence_pair[0]\n",
    "    t_sentence = sentence_pair[1]\n",
    "    s_length = len(s_sentence)\n",
    "    t_length = len(t_sentence)\n",
    "    best_alignment = set()\n",
    "    for t_pos, t_word in enumerate(t_sentence):\n",
    "        best_align_prob = -1\n",
    "        best_align_pos = -1\n",
    "        for s_pos, s_word in enumerate(s_sentence):\n",
    "            if s_word not in lprobs.keys() or t_word not in lprobs[s_word].keys():\n",
    "                continue # ignore unseen source and target words\n",
    "            align_prob = get_alignment_prob(s_pos, t_pos, s_length, t_length, jump_probs) * lprobs[s_word][t_word] \n",
    "            if align_prob >= best_align_prob:\n",
    "                best_align_pos = s_pos\n",
    "                best_align_prob = align_prob\n",
    "        if (best_align_pos > 0): # Leave out NULL-alignments (and alignments between unseen words)\n",
    "            best_alignment.add((best_align_pos, t_pos + 1)) # word positions start at 1\n",
    "    return best_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM(s_t_pairs, s_vocabulary, t_vocabulary, max_iterations = 10,\n",
    "        val_sentence_pairs = None, reference_alignments = None, fn_debug = None):\n",
    "    lprobs = _initialize_lexicon_probabilities(s_vocabulary, t_vocabulary)\n",
    "    jump_probs = _initialize_jump_probs(s_t_pairs)\n",
    "#    print('initial jump probs', jump_probs)\n",
    "    i = 0\n",
    "    log_likelihoods = []\n",
    "    AERs = []\n",
    "    while i < max_iterations:\n",
    "        print(datetime.datetime.now().strftime(\"%I:%M\"), ':', i)\n",
    "        \n",
    "        # initialize\n",
    "        log_likelihood = 0\n",
    "        AER = 0\n",
    "        counts_t_given_s = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "        total_s = collections.defaultdict(int)\n",
    "        jump_counts = [0]*len(jump_probs)\n",
    "\n",
    "        # calculate counts and log likelihood\n",
    "        for (s_sentence, t_sentence) in s_t_pairs:\n",
    "            s_length = len(s_sentence)\n",
    "            t_length = len(t_sentence)\n",
    "            for t_pos, t_word in enumerate(t_sentence):\n",
    "                prob_counts = source_dependencies(\n",
    "                    s_sentence, t_word, t_pos, t_length, lprobs, jump_probs)\n",
    "                s_total_t = sum(prob_counts)\n",
    "                log_likelihood += math.log(s_total_t)\n",
    "                                \n",
    "                for s_pos, s_word in enumerate(s_sentence):\n",
    "                    update = prob_counts[s_pos]/s_total_t\n",
    "                    counts_t_given_s[s_word][t_word] += update\n",
    "                    total_s[s_word] += update\n",
    "                    jump_count_index = get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "                    jump_counts[jump_count_index] += update \n",
    " #                   print('jump_update', jump_count_index, '%.2f' % update, s_word, t_word)\n",
    "        \n",
    "        # store log_likelihood and AER values\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "        if val_sentence_pairs and reference_alignments:\n",
    "            predicted_alignments = align(lprobs, jump_probs, val_sentence_pairs)\n",
    "            AER = aer.calculate_AER(reference_alignments, predicted_alignments)\n",
    "            AERs.append(AER)\n",
    "\n",
    "        # print debug info\n",
    "        if fn_debug:\n",
    "            fn_debug(i, lprobs, log_likelihood, AER)\n",
    "\n",
    "        # update probabilities\n",
    "        for s in lprobs.keys():\n",
    "            for t in lprobs[s].keys():\n",
    "                lprobs[s][t] = counts_t_given_s[s][t]/total_s[s]\n",
    "        \n",
    "  #      print('jump_counts', [\"%.2f\"%item for item in jump_counts])\n",
    "        jump_count_sum = sum(jump_counts)\n",
    "        jump_probs = [jc/jump_count_sum for jc in jump_counts]\n",
    "    #    print(f'i:{i}, jump_probs:{[\"%.2f\"%item for item in jump_probs]}')\n",
    "\n",
    "        # update iteration number\n",
    "        i += 1\n",
    "    return lprobs, jump_probs, log_likelihoods, AERs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_word_order()\n",
    "s_t_pairs\n",
    "(lprobs, jump_probs, _, _) = EM(s_t_pairs, s_vocabulary, t_vocabulary, \n",
    "                 fn_debug = debug_helpers.print_likelihood) #debug_helpers.print_likelihood debug_helpers.print_lexicon_probs\n",
    "\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['<NULL>', 'das', 'Haus'], ['the', 'house']),\n",
       " (['<NULL>', 'das', 'Buch'], ['the', 'book']),\n",
       " (['<NULL>', 'ein', 'Buch'], ['a', 'book'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:01 : 0\n",
      "iteration  log_likelihood  likelihood  AER\n",
      "0 -10.751 0.000 0.00000\n",
      "12:01 : 1\n",
      "1 -5.890 0.003 0.00000\n",
      "12:01 : 2\n",
      "2 -3.553 0.029 0.00000\n",
      "12:01 : 3\n",
      "3 -1.006 0.366 0.00000\n",
      "12:01 : 4\n",
      "4 -0.246 0.782 0.00000\n",
      "12:01 : 5\n",
      "5 -0.078 0.925 0.00000\n",
      "12:01 : 6\n",
      "6 -0.025 0.975 0.00000\n",
      "12:01 : 7\n",
      "7 -0.008 0.992 0.00000\n",
      "12:01 : 8\n",
      "8 -0.003 0.997 0.00000\n",
      "12:01 : 9\n",
      "9 -0.001 0.999 0.00000\n",
      "<NULL> the 0.4991292185033461\n",
      "<NULL> house 0.0008707814966539814\n",
      "<NULL> book 0.4991292185033461\n",
      "<NULL> a 0.0008707814966539814\n",
      "das the 1.0\n",
      "das house 5.759195849526883e-243\n",
      "das book 3.467226178467145e-243\n",
      "Haus the 1.7113802053279e-240\n",
      "Haus house 1.0\n",
      "Buch the 3.467226178467062e-243\n",
      "Buch book 1.0\n",
      "Buch a 5.759195849526748e-243\n",
      "ein a 1.0\n",
      "ein book 1.711380205327941e-240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.883050489433111e-241,\n",
       " 0.9999246503574676,\n",
       " 2.8830504894330416e-241,\n",
       " 7.534964253244149e-05]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run EM on toy example\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs[0:3]\n",
    "(lprobs, jump_probs, _, _) = EM(s_t_pairs[0:3], s_vocabulary, t_vocabulary, \n",
    "                 fn_debug = debug_helpers.print_likelihood)\n",
    "\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['<NULL>', 'das', 'Haus'], ['the', 'house']),\n",
       " (['<NULL>', 'das', 'Buch'], ['the', 'book']),\n",
       " (['<NULL>', 'ein', 'Buch'], ['a', 'book']),\n",
       " (['<NULL>', 'ein', 'Haus'], ['a', 'small', 'house']),\n",
       " (['<NULL>', 'mein', 'Buch'], ['my', 'small', 'book'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:01 : 0\n",
      "iteration  log_likelihood  likelihood  AER\n",
      "0 -21.501 0.000 0.50000\n",
      "12:01 : 1\n",
      "1 -16.406 0.000 1.00000\n",
      "12:01 : 2\n",
      "2 -11.866 0.000 1.00000\n",
      "12:01 : 3\n",
      "3 -7.532 0.001 1.00000\n",
      "12:01 : 4\n",
      "4 -5.653 0.004 1.00000\n",
      "12:01 : 5\n",
      "5 -4.928 0.007 1.00000\n",
      "12:01 : 6\n",
      "6 -4.652 0.010 1.00000\n",
      "12:01 : 7\n",
      "7 -4.547 0.011 1.00000\n",
      "12:01 : 8\n",
      "8 -4.507 0.011 1.00000\n",
      "12:01 : 9\n",
      "9 -4.494 0.011 1.00000\n",
      "12:01 : 10\n",
      "10 -4.494 0.011 1.00000\n",
      "12:01 : 11\n",
      "11 -4.500 0.011 1.00000\n",
      "12:01 : 12\n",
      "12 -4.509 0.011 1.00000\n",
      "12:01 : 13\n",
      "13 -4.521 0.011 1.00000\n",
      "12:01 : 14\n",
      "14 -4.536 0.011 1.00000\n",
      "12:01 : 15\n",
      "15 -4.553 0.011 1.00000\n",
      "12:01 : 16\n",
      "16 -4.571 0.010 1.00000\n",
      "12:01 : 17\n",
      "17 -4.591 0.010 1.00000\n",
      "12:01 : 18\n",
      "18 -4.612 0.010 1.00000\n",
      "12:01 : 19\n",
      "19 -4.633 0.010 1.00000\n",
      "<NULL> the 3.435972729711346e-13\n",
      "<NULL> house 5.022798347214058e-13\n",
      "<NULL> book 9.983477528928095e-10\n",
      "<NULL> a 0.37979799545065424\n",
      "<NULL> small 5.710624066074272e-07\n",
      "<NULL> my 0.6202014324877455\n",
      "das the 1.0\n",
      "Haus the 7.36188380398008e-22\n",
      "Haus house 0.9999999999999234\n",
      "Haus small 7.656096908153313e-14\n",
      "Buch the 3.966189793896714e-25\n",
      "Buch book 1.0\n",
      "Buch a 4.282038753155334e-22\n",
      "Buch small 3.1141228027355616e-21\n",
      "ein a 0.6085055107717902\n",
      "ein small 0.3914944892282098\n",
      "mein my 0.2139628530102402\n",
      "mein small 0.7860371469897598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maartje/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Jump prob index 5 (jump:3) out of range.\n",
      "/home/maartje/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Jump prob index -1 (jump:-3) out of range.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.8283837307250819, 0.07382605711232869, 0.0, 0.09779021216258932]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run EM on toy example with NULL words\n",
    "val_sentence_pairs = [(\n",
    "    ['<NULL>', 'Buch', 'klein', 'das', 'Haus'], \n",
    "    ['book', 'small', 'the', 'house']\n",
    ")]\n",
    "ref_alignments = [[\n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}, \n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}\n",
    "]]\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs\n",
    "(lprobs, jump_probs, _, _) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 20,\n",
    "    val_sentence_pairs, ref_alignments, debug_helpers.print_likelihood)\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:01 : 0\n",
      "iteration  log_likelihood  likelihood  AER\n",
      "0 -49501757.944 0.000 0.92877\n",
      "02:16 : 1\n",
      "1 -22598368.778 0.000 0.28848\n",
      "04:32 : 2\n",
      "2 -18009753.946 0.000 0.25570\n",
      "06:49 : 3\n",
      "3 -16335263.053 0.000 0.24335\n",
      "09:06 : 4\n"
     ]
    }
   ],
   "source": [
    "# Run EM on training data set with AER on validation set\n",
    "val_sentence_pairs, _, _ = datasets.validation_data()\n",
    "reference_alignments = datasets.validation_alignments()    \n",
    "\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.training_data()\n",
    "(lprobs, jump_probs, log_lhoods, AERs) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 30,\n",
    "    val_sentence_pairs, reference_alignments, \n",
    "    debug_helpers.print_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-29 23:57:38.713576\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:59'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%I:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
