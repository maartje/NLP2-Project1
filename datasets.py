import aer
from collections import Counter

# (...) We are assuming that French words are generated by English 
# words, and that the NULL word is therefore on the English side (...).
def training_data():
    s_path = "training/hansards.36.2.e"
    t_path = "training/hansards.36.2.f"
    
    # source: add <NULL> words and replace infrequent words with <LOW>
    s_sentences = list(_read_sentences(s_path))
    s_sentences = _add_null_words(s_sentences)
    (s_sentences, s_vocabulary) = _replace_low_frequency_words(s_sentences)
    
    # target: replace infrequent words with <LOW>
    t_sentences = list(_read_sentences(t_path))
    (t_sentences, t_vocabulary) = _replace_low_frequency_words(t_sentences)
    
    # create pairs
    s_t_pairs = list(zip(s_sentences, t_sentences))
    
    return s_t_pairs, s_vocabulary, t_vocabulary


def validation_data(s_vocabulary, t_vocabulary):
    return _evaluation_data("validation/dev.e", "validation/dev.f", s_vocabulary, t_vocabulary)

def test_data(s_vocabulary, t_vocabulary):
    return _evaluation_data("testing/test/test.e", "testing/test/test.f", s_vocabulary, t_vocabulary)

def _evaluation_data(s_path, t_path, s_vocabulary, t_vocabulary):
    
    # source: add <NULL> words and replace unknown words with <LOW>
    s_sentences = list(_read_sentences(s_path))
    s_sentences = _add_null_words(s_sentences)
    s_sentences = _replace_unknown_words(s_sentences, s_vocabulary)
    
    # target: replace unknown words with <LOW>
    t_sentences = list(_read_sentences(t_path))
    t_sentences = _replace_unknown_words(t_sentences, t_vocabulary)

    # create pairs
    s_t_pairs = list(zip(s_sentences, t_sentences))
    return s_t_pairs


def corpus_data(s_path, t_path):
    s_sentences = list(_read_sentences(s_path))
    t_sentences = list(_read_sentences(t_path))
    return _process_sentences(s_sentences, t_sentences)

def example_data():
    german_sentences = [['das', 'Haus'], ['das', 'Buch'], ['ein', 'Buch']]
    english_sentences = [['the', 'house'], ['the', 'book'], ['a', 'book']]
    return _process_sentences(german_sentences, english_sentences, add_null_words = False)

def example_data_null_words():
    german_sentences = [['das', 'Haus'], ['das', 'Buch'], ['ein', 'Buch'], 
        ['ein', 'Haus'], ['mein', 'Buch']]
    english_sentences = [['the', 'house'], ['the', 'book'], ['a', 'book'], 
        ['a', 'small', 'house'], ['my', 'small', 'book']]
    return _process_sentences(german_sentences, english_sentences)

def example_data_word_order():
    german_sentences = [['Haus', 'das'], ['Buch', 'das'], ['Buch', 'ein'], 
        ['Maus', 'ein'], ['Hund', 'das'], ['Welt', 'ein'], ['Boot', 'das'],
        ['Brugge', 'ein']]
    english_sentences = [['the', 'house'], ['the', 'book'], ['a', 'book'], 
        ['a', 'mouse'], ['the', 'dog'], ['a', 'world'], ['the', 'boat'],
        ['a', 'bridge']]
    return _process_sentences(german_sentences, english_sentences)

def validation_alignments():
    val_naacl_path = 'validation/dev.wa.nonullalign'
    reference_alignments = aer.read_naacl_alignments(val_naacl_path) 
    return reference_alignments

def _read_sentences(fpath):
    with open(fpath, 'r') as lines:
        for line in lines:
            yield line.split()

def _process_sentences(s_sentences, t_sentences, add_null_words = True):
    if add_null_words:
        s_sentences = _add_null_words(s_sentences)
    s_vocabulary = _build_vocabulary(s_sentences)
    t_vocabulary = _build_vocabulary(t_sentences)
    s_t_pairs = list(zip(s_sentences, t_sentences))
    return s_t_pairs, s_vocabulary, t_vocabulary

def _add_null_words(sentences):
    return [['<NULL>'] + s for s in sentences]

def _build_vocabulary(sentences):
    return list({word for sentence in sentences for word in sentence})

def _replace_low_frequency_words(sentences):
    words = [w  for s in sentences for w in s]
    word_counts = Counter(words)
    vocabulary = set(words)
    vocabulary_counts = Counter(vocabulary)
    frequent_word_counts = word_counts - vocabulary_counts
    vocabulary_frequent_words = list(frequent_word_counts.keys())
    if len(vocabulary_frequent_words) == len(vocabulary):
        raise('We just assume that infrequent words exist ...')
    vocabulary_frequent_words.append('<LOW>')
    sentences_frequent_words = _replace_unknown_words(sentences, vocabulary_frequent_words)
    return (sentences_frequent_words, vocabulary_frequent_words)

def _replace_unknown_words(sentences, vocabulary):
    replace_infrequent = lambda w: w if w in vocabulary else '<LOW>'
    return [[replace_infrequent(w) for w in s] for s in sentences ] 

