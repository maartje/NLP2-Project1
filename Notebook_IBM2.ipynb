{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datasets\n",
    "import debug_helpers\n",
    "import datetime\n",
    "\n",
    "import collections\n",
    "import aer\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import persistence\n",
    "import plots\n",
    "import random\n",
    "import convergence_criterion as cc\n",
    "\n",
    "\n",
    "# pretty print variabeles on line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns list with jump probabilities \n",
    "# (and special NULL jump probability)\n",
    "# [-max_jump ....0 ...max_jump, NULL_jump]\n",
    "def initialize_jump_probs_uniformly(sentence_pairs):\n",
    "    max_jump = 0\n",
    "    for (s_sentence, t_sentence) in sentence_pairs:\n",
    "        s_length = len(s_sentence) - 1 #ignore NULL\n",
    "        t_length = len(t_sentence)\n",
    "        jump_1 = abs(1 - math.floor(s_length))\n",
    "        jump_2 = abs(s_length - math.floor(s_length/t_length))\n",
    "        max_jump = max(jump_1, jump_2, max_jump)\n",
    "    init_prob = 1. / (2*max_jump + 1 + 1) # last item is special NULL jump prob\n",
    "    return [init_prob] * (2*max_jump + 1 + 1)\n",
    "\n",
    "def initialize_jump_probs_randomly(sentence_pairs):\n",
    "    max_jump = 0\n",
    "    for (s_sentence, t_sentence) in sentence_pairs:\n",
    "        s_length = len(s_sentence) - 1 #ignore NULL\n",
    "        t_length = len(t_sentence)\n",
    "        jump_1 = abs(1 - math.floor(s_length))\n",
    "        jump_2 = abs(s_length - math.floor(s_length/t_length))\n",
    "        max_jump = max(jump_1, jump_2, max_jump)\n",
    "    probs_length = 2*max_jump + 1 + 1 # last item is special NULL jump prob\n",
    "    randoms = [random.random() for i in range(probs_length)]\n",
    "    sum_randoms = sum(randoms)\n",
    "    return [r/sum_randoms for r in randoms]\n",
    "\n",
    "# returns the index in the jump_probabilities list\n",
    "# for given source and target positions and sentence lengths\n",
    "# s_pos and s_length for source sentence including the special NULL word\n",
    "# sentence positions start at index 0\n",
    "def get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    if s_pos == 0:\n",
    "        return len(jump_probs) - 1\n",
    "    jump = int(s_pos - math.floor((t_pos + 1) * (s_length - 1) / t_length))\n",
    "    max_jump = int((len(jump_probs) - 2)/2)\n",
    "    jump_prob_index = jump + max_jump\n",
    "    if jump_prob_index < 0:\n",
    "        warnings.warn(\n",
    "            f'Jump prob index {jump_prob_index} (jump:{jump}) out of range.'\n",
    "        )\n",
    "        return 0 #approximate with prob of largest negative jump\n",
    "    if jump_prob_index >= len(jump_probs) - 1:\n",
    "        warnings.warn(\n",
    "            f'Jump prob index {jump_prob_index} (jump:{jump}) out of range.'\n",
    "        )\n",
    "        return len(jump_probs) - 2 #approximate with prob of largest positive jump\n",
    "\n",
    "    return jump_prob_index\n",
    "\n",
    "# returns jump probability for given source and target positions\n",
    "# and lengths. Positions start at index 0, source sentence contains\n",
    "# special NULL word at position 0\n",
    "def get_jump_prob(s_pos, t_pos, s_length, t_length, jump_probs):\n",
    "    jump_prob_index = get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "    return jump_probs[jump_prob_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {Hause: { book:0.25, ...}, ...}\n",
    "# read: the probability of 'book' given 'Haus' is 0.25\n",
    "def initialize_lprobs_uniform(s_t_pairs, target_vocabulary):\n",
    "    p_init = 1./len(target_vocabulary)\n",
    "    lexicon_probabilities = collections.defaultdict(\n",
    "        lambda: collections.defaultdict(lambda: p_init))\n",
    "    return lexicon_probabilities\n",
    "\n",
    "def initialize_lprobs_staged(s_t_pairs, target_vocabulary):\n",
    "    return load_ibm1_model('ibm1_iter_5.txt')\n",
    "\n",
    "def initialize_lprobs_randomly(s_t_pairs, target_vocabulary):\n",
    "    # find all word combinations in sentence pairs\n",
    "    s_t_combinations = ((s_word, t_word) \n",
    "          for (s_sentence, t_sentence) in s_t_pairs \n",
    "          for s_word in s_sentence \n",
    "          for t_word in t_sentence)\n",
    "\n",
    "    # set random probabilities for word combinations\n",
    "    lprobs = collections.defaultdict(lambda: collections.defaultdict(lambda: float('NaN')))\n",
    "    for (s, t) in s_t_combinations:\n",
    "        lprobs[s][t] = random.random()\n",
    "\n",
    "    # normalize probabilities\n",
    "    for s_key, t_dict in lprobs.items():\n",
    "        total = sum(t_dict.values())\n",
    "        for (t_key, r) in t_dict.items():\n",
    "            t_dict[t_key] = t_dict[t_key] / total\n",
    "    return lprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_dependencies(s_sentence, t_word, t_pos, t_length, lprobs, jump_probs):\n",
    "    s_length = len(s_sentence)    \n",
    "    jump_probs = [get_jump_prob(\n",
    "        s_word_pos, t_pos, s_length, t_length, jump_probs\n",
    "    ) for s_word_pos in range(s_length)]\n",
    "    sum_jump_probs = sum(jump_probs)\n",
    "    \n",
    "    return [\n",
    "        (jump_probs[s_pos]/ sum_jump_probs) * lprobs[s_word][t_word] \n",
    "        for s_pos, s_word in enumerate(s_sentence)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align(lprobs, jump_probs, sentence_pairs):\n",
    "    if isinstance(sentence_pairs, tuple):\n",
    "        return _align_sentence_pair(lprobs, jump_probs, sentence_pairs)\n",
    "    return [ _align_sentence_pair(lprobs, jump_probs, sentence_pair) for sentence_pair in sentence_pairs ]\n",
    "\n",
    "def _align_sentence_pair(lprobs, jump_probs, sentence_pair):\n",
    "    s_sentence = sentence_pair[0]\n",
    "    t_sentence = sentence_pair[1]\n",
    "    s_length = len(s_sentence)\n",
    "    t_length = len(t_sentence)\n",
    "    best_alignment = set()\n",
    "    for t_pos, t_word in enumerate(t_sentence):\n",
    "        sd = source_dependencies(s_sentence, t_word, t_pos, t_length, lprobs, jump_probs)\n",
    "        (best_align_pos, _) = max(enumerate(sd), key=lambda t: t[1])\n",
    "        if (best_align_pos > 0): # Leave out NULL-alignments (and alignments between unseen words)\n",
    "            best_alignment.add((best_align_pos, t_pos + 1)) # word positions start at 1\n",
    "    return best_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM(s_t_pairs, s_vocabulary, t_vocabulary, fn_init_lprobs, fn_init_jump_probs, max_iterations = 10,\n",
    "        val_sentence_pairs = None, reference_alignments = None, fn_debug = None):\n",
    "    lprobs = fn_init_lprobs(s_t_pairs, t_vocabulary)\n",
    "    jump_probs = fn_init_jump_probs(s_t_pairs)\n",
    "#    print('initial jump probs', jump_probs)\n",
    "    i = 0\n",
    "    log_likelihoods = []\n",
    "    AERs = []\n",
    "    while i < max_iterations:\n",
    "        \n",
    "        # initialize\n",
    "        log_likelihood = 0\n",
    "        AER = 0\n",
    "        counts_t_given_s = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "        total_s = collections.defaultdict(int)\n",
    "        jump_counts = [0]*len(jump_probs)\n",
    "\n",
    "        # calculate counts and log likelihood\n",
    "        for (s_sentence, t_sentence) in s_t_pairs:\n",
    "            s_length = len(s_sentence)\n",
    "            t_length = len(t_sentence)\n",
    "            for t_pos, t_word in enumerate(t_sentence):\n",
    "                prob_counts = source_dependencies(\n",
    "                    s_sentence, t_word, t_pos, t_length, lprobs, jump_probs)\n",
    "                s_total_t = sum(prob_counts)\n",
    "                log_likelihood += math.log(s_total_t)\n",
    "                                \n",
    "                for s_pos, s_word in enumerate(s_sentence):\n",
    "                    update = prob_counts[s_pos]/s_total_t\n",
    "                    counts_t_given_s[s_word][t_word] += update\n",
    "                    total_s[s_word] += update\n",
    "                    jump_count_index = get_jump_prob_index(s_pos, t_pos, s_length, t_length, jump_probs)\n",
    "                    jump_counts[jump_count_index] += update \n",
    "        \n",
    "        # store log_likelihood and AER values\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "        if val_sentence_pairs and reference_alignments:\n",
    "            predicted_alignments = align(lprobs, jump_probs, val_sentence_pairs)\n",
    "            AER = aer.calculate_AER(reference_alignments, predicted_alignments)\n",
    "            AERs.append(AER)\n",
    "\n",
    "        # print debug info\n",
    "        if fn_debug:\n",
    "            fn_debug(i, lprobs, log_likelihood, AER, jump_probs)\n",
    "\n",
    "        # update probabilities\n",
    "        for s in lprobs.keys():\n",
    "            for t in lprobs[s].keys():\n",
    "                lprobs[s][t] = counts_t_given_s[s][t]/total_s[s]\n",
    "        \n",
    "        jump_count_sum = sum(jump_counts)\n",
    "        jump_probs = [jc/jump_count_sum for jc in jump_counts]\n",
    "\n",
    "        # update iteration number\n",
    "        i += 1\n",
    "\n",
    "    # add AER after final update\n",
    "    if val_sentence_pairs and reference_alignments:\n",
    "        predicted_alignments = align(lprobs, jump_probs, val_sentence_pairs)\n",
    "        AER = aer.calculate_AER(reference_alignments, predicted_alignments)\n",
    "        AERs.append(AER)\n",
    "    \n",
    "    # add llhood after final update\n",
    "    log_likelihood = 0\n",
    "    for (s_sentence, t_sentence) in s_t_pairs:\n",
    "        s_length = len(s_sentence)\n",
    "        t_length = len(t_sentence)\n",
    "        for t_pos, t_word in enumerate(t_sentence):\n",
    "            prob_counts = source_dependencies(\n",
    "                s_sentence, t_word, t_pos, t_length, lprobs, jump_probs)\n",
    "            s_total_t = sum(prob_counts)\n",
    "            log_likelihood += math.log(s_total_t)\n",
    "\n",
    "    return lprobs, jump_probs, log_likelihoods, AERs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['<NULL>', 'Haus', 'das'], ['the', 'house']),\n",
       " (['<NULL>', 'Buch', 'das'], ['the', 'book']),\n",
       " (['<NULL>', 'Buch', 'ein'], ['a', 'book']),\n",
       " (['<NULL>', 'Maus', 'ein'], ['a', 'mouse']),\n",
       " (['<NULL>', 'Hund', 'das'], ['the', 'dog']),\n",
       " (['<NULL>', 'Welt', 'ein'], ['a', 'world']),\n",
       " (['<NULL>', 'Boot', 'das'], ['the', 'boat']),\n",
       " (['<NULL>', 'Brugge', 'ein'], ['a', 'bridge'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NULL> the 0.020652063779340684\n",
      "<NULL> house 2.1179055020546916e-06\n",
      "<NULL> book 0.0059541288292568875\n",
      "<NULL> a 0.9732644711716477\n",
      "<NULL> mouse 1.6654433234606247e-05\n",
      "<NULL> dog 1.1984256496985133e-05\n",
      "<NULL> world 5.143059109009515e-05\n",
      "<NULL> boat 1.759753189224704e-05\n",
      "<NULL> bridge 2.955150153886354e-05\n",
      "Haus the 4.0504087253456016e-55\n",
      "Haus house 1.0\n",
      "das the 1.0\n",
      "das house 1.1405058530124724e-60\n",
      "das book 1.9874581177926453e-60\n",
      "das dog 1.671852193686713e-60\n",
      "das boat 4.866590363376503e-60\n",
      "Buch the 1.333086453565642e-57\n",
      "Buch book 1.0\n",
      "Buch a 1.735099399591696e-57\n",
      "ein a 1.0\n",
      "ein book 3.4544117846614407e-60\n",
      "ein mouse 1.7345912888081604e-60\n",
      "ein world 1.7551513924707825e-59\n",
      "ein bridge 5.143073730944358e-60\n",
      "Maus a 5.233220822512758e-55\n",
      "Maus mouse 1.0\n",
      "Hund the 4.560746661678686e-55\n",
      "Hund dog 1.0\n",
      "Welt a 6.96792795226332e-55\n",
      "Welt world 1.0\n",
      "Boot the 5.140761599554433e-55\n",
      "Boot boat 1.0\n",
      "Brugge a 5.7621701351819685e-55\n",
      "Brugge bridge 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49999963067365616,\n",
       " 1.9861312764393637e-55,\n",
       " 0.49993965946101243,\n",
       " 6.070986533146486e-05]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_word_order()\n",
    "(lprobs, jump_probs, _, _) = EM(s_t_pairs, s_vocabulary, t_vocabulary, \n",
    "                                initialize_lprobs_randomly, initialize_jump_probs_randomly,\n",
    "                 fn_debug = None) #debug_helpers.print_likelihood debug_helpers.print_lexicon_probs\n",
    "\n",
    "# assert(round(lprobs['Haus']['house'], 5) == 1.)\n",
    "# assert(round(lprobs['Welt']['world'], 5) == 1.)\n",
    "# assert(round(lprobs['das']['the'], 5) == 1.)\n",
    "# assert(round(lprobs['<NULL>']['house'], 5) == 0.)\n",
    "# assert(round(lprobs['<NULL>']['the'], 5) == 0.49987)\n",
    "\n",
    "# assert(round(jump_probs[0], 5) == 0.49999)\n",
    "# assert(round(jump_probs[1], 5) == 0.0)\n",
    "# assert(round(jump_probs[2], 5) == 0.48086)\n",
    "# assert(round(jump_probs[3], 5) == 0.01915)\n",
    "\n",
    "# print('PASSED!')\n",
    "\n",
    "s_t_pairs\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EM on toy example\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs[0:3]\n",
    "(lprobs, jump_probs, _, _) = EM(s_t_pairs[0:3], s_vocabulary, t_vocabulary, \n",
    "                 fn_debug = debug_helpers.print_likelihood)\n",
    "\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EM on toy example with NULL words\n",
    "val_sentence_pairs = [(\n",
    "    ['<NULL>', 'Buch', 'klein', 'das', 'Haus'], \n",
    "    ['book', 'small', 'the', 'house']\n",
    ")]\n",
    "ref_alignments = [[\n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}, \n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}\n",
    "]]\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs\n",
    "(lprobs, jump_probs, _, _) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 20,\n",
    "    val_sentence_pairs, ref_alignments, debug_helpers.print_likelihood)\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "jump_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fname_ibm2(i):\n",
    "    return f'ibm2_iter_{i}.txt'\n",
    "\n",
    "# After each iteration we print llhood and AER and store the model \n",
    "# We can later load the models that meet our convergence criteria\n",
    "# and apply those to the test data\n",
    "def fn_after_iter_ibm2(i, lprobs, log_likelihood, AER, jump_probs):\n",
    "    debug_helpers.print_likelihood(i, lprobs, log_likelihood, AER)\n",
    "#    if (i == 7) or (i == 9): # AER and LLhoods\n",
    "#        persistence.save_ibm2_model(lprobs, jump_probs, fname_ibm2(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run EM on training data set with AER on validation set\n",
    "# *** uniform initialization\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.training_data()\n",
    "val_sentence_pairs = datasets.validation_data(s_vocabulary, t_vocabulary)\n",
    "reference_alignments = datasets.validation_alignments()    \n",
    "\n",
    "(lprobs, jump_probs, llhoods, AERs) = EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 15,\n",
    "    initialize_lprobs_uniform,\n",
    "    val_sentence_pairs, reference_alignments, \n",
    "    fn_after_iter_ibm2)\n",
    "\n",
    "\n",
    "# plot AER and llhood scores vs iteration\n",
    "plots.figure_log_likelihood(llhoods, 'IBM2')\n",
    "plots.figure_AER(AERs, 'IBM2')\n",
    "\n",
    "# select models based on AER and llhood selection criterion\n",
    "selected_model_AER = fname_ibm2(cc.select_model_AER(AERs))\n",
    "selected_model_llhood = fname_ibm2(cc.select_model_LLhood(llhoods))\n",
    "print('model selected on AER:', selected_model_AER)\n",
    "print('model selected on LLhood:', selected_model_llhood)\n",
    "\n",
    "# store AER and llhood scores in file\n",
    "fname_ibm2_AERs = \"ibm2_AERs_iter15.txt\"    \n",
    "fname_ibm2_llhoods = \"ibm2_llhoods_iter15.txt\"\n",
    "persistence.save(AERs, fname_ibm2_AERs)\n",
    "persistence.save(llhoods, fname_ibm2_llhoods)\n",
    "\n",
    "# store model\n",
    "#persistence.save_ibm2_model(lprobs, jump_probs, fname_ibm2(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.training_data()\n",
    "val_sentence_pairs = datasets.validation_data(s_vocabulary, t_vocabulary)\n",
    "reference_alignments = datasets.validation_alignments()    \n",
    "\n",
    "# Run EM on training data set with AER on validation set\n",
    "# using random initialization (3x)\n",
    "run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_randomly, 'random_random_1')\n",
    "run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_randomly, 'random_random_2')\n",
    "run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_randomly, 'random_random_3')\n",
    "\n",
    "# Run EM on training data set with AER on validation set\n",
    "# using initialization with IBM 1 und uniform jump probabilities\n",
    "run_em_with_initialization(initialize_lprobs_staged, initialize_jump_probs_uniformly, 'staged')\n",
    "\n",
    "# run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_uniformly, 'random_unform_1')\n",
    "# run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_uniformly, 'random_unform_2')\n",
    "# run_em_with_initialization(initialize_lprobs_randomly, initialize_jump_probs_uniformly, 'random_unform_3')\n",
    "\n",
    "def run_em_with_initialization(fn_init, fn_init_jumps, init_name):\n",
    "    (lprobs, jump_probs, llhoods, AERs) = EM (\n",
    "        s_t_pairs, s_vocabulary, t_vocabulary, 15,\n",
    "        fn_init, fn_init_jumps,\n",
    "        val_sentence_pairs, reference_alignments, \n",
    "        fn_after_iter_ibm2)\n",
    "\n",
    "    # store AER and llhood scores in file\n",
    "    fname_ibm2_AERs = f'ibm2_AERs_{init_name}.txt'    \n",
    "    fname_ibm2_llhoods = f'ibm2_llhoods_{init_name}.txt'\n",
    "    persistence.save(AERs, fname_ibm2_AERs)\n",
    "    persistence.save(llhoods, fname_ibm2_llhoods)\n",
    "\n",
    "    # select models based on AER and llhood selection criterion\n",
    "    selected_model_AER = fname_ibm2(cc.select_model_AER(AERs))\n",
    "    selected_model_llhood = fname_ibm2(cc.select_model_LLhood(llhoods))\n",
    "    print(f'model selected on AER for {init_name}:', selected_model_AER)\n",
    "    print(f'model selected on LLhood for {init_name}:', selected_model_llhood)\n",
    "\n",
    "    # plot AER and llhood scores vs iteration\n",
    "    plots.figure_log_likelihood(llhoods, f'IBM2_{init_name}')\n",
    "    plots.figure_AER(AERs, f'IBM2_{init_name}')\n",
    "\n",
    "# store model\n",
    "#persistence.save_ibm2_model(lprobs, jump_probs, fname_ibm2(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
