{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datasets\n",
    "import IBM1 as ibm1\n",
    "import debug_helpers\n",
    "\n",
    "# pretty print variabeles on line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EM on toy example\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data()\n",
    "s_t_pairs\n",
    "(lprobs, _, _) = ibm1.EM(s_t_pairs, s_vocabulary, t_vocabulary, \n",
    "                 fn_debug = debug_helpers.print_likelihood)\n",
    "\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EM on toy example with NULL words\n",
    "val_sentence_pairs = [(\n",
    "    ['<NULL>', 'Buch', 'klein', 'das', 'Haus'], \n",
    "    ['the', 'small', 'house', 'book']\n",
    ")]\n",
    "ref_alignments = [[\n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}, \n",
    "    {(3, 1), (2, 2), (4, 3), (1, 4)}\n",
    "]]\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.example_data_null_words()\n",
    "s_t_pairs\n",
    "(lprobs, _, _) = ibm1.EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 20,\n",
    "    val_sentence_pairs, ref_alignments, debug_helpers.print_likelihood)\n",
    "debug_helpers.print_lexicon_probs(None, lprobs, None, None)\n",
    "\n",
    "# QUESTION: how can likelihood be bigger than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EM on training data set with AER on validation set\n",
    "val_sentence_pairs, _, _ = datasets.validation_data()\n",
    "reference_alignments = datasets.validation_alignments()    \n",
    "\n",
    "s_t_pairs, s_vocabulary, t_vocabulary = datasets.training_data()\n",
    "(lprobs, log_lhoods, AERs) = ibm1.EM(\n",
    "    s_t_pairs, s_vocabulary, t_vocabulary, 30,\n",
    "    val_sentence_pairs, reference_alignments, \n",
    "    debug_helpers.print_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_data(s_t_pairs, lprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_helpers.print_learned_translations(lprobs, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "fname = 'probs_ibm1_iter30.txt'\n",
    "json.dump(lprobs, open(fname,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "fname = 'probs_ibm1_iter30.txt'\n",
    "probs_ibm1_iter_10 = json.load(open(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_ibm1_iter_10['population']['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loglhoods_ibm1_iter30.txt\", \"w\") as file:\n",
    "    file.write(str(log_lhoods))\n",
    "    \n",
    "with open(\"AERs_ibm1_iter30.txt\", \"w\") as file:\n",
    "    file.write(str(AERs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as file:\n",
    "    data2 = eval(file.readline())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
